{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boJp2OqlGcyP",
        "outputId": "f301e4f0-746e-4a18-8f4b-93e978356b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.4-py3-none-any.whl (310 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.74-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.2 langchain-core-0.2.4 langchain-text-splitters-0.2.1 langsmith-0.1.74 orjson-3.10.3 packaging-23.2\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.5.4)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.2.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-google-genai) (0.1.74)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-google-genai) (8.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-google-genai) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.18.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.63.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-google-genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-google-genai) (2024.6.2)\n",
            "Installing collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# Twitter\n",
        "import tweepy"
      ],
      "metadata": {
        "id": "bfpmkilrG9xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "google_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "S2oz3gFiHiZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# sample check\n",
        "llm = ChatGoogleGenerativeAI(google_api_key=google_api_key, model=\"gemini-pro\")\n",
        "llm.invoke(\"Sing a ballad of LangChain.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKyU0Fi9HxUP",
        "outputId": "ec13afc6-002b-4f41-84c4-1eb2bbd3c09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"In realms of code, a tale unfolds,\\nOf LangChain, a knight, with queries bold.\\nA master of language, vast and deep,\\nIts prowess unmatched, secrets it shall keep.\\n\\nWith every query, a journey it embarks,\\nThrough words and phrases, leaving its marks.\\nIt delves into meanings, both hidden and plain,\\nUnraveling the tapestry of human refrain.\\n\\nFrom simple commands to profound discourse,\\nLangChain navigates with unwavering force.\\nIt bridges the gap between mind and machine,\\nTranslating thoughts into a digital scene.\\n\\nIn chatbots and assistants, it finds its voice,\\nGuiding users with wisdom and poise.\\nIts algorithms dance, a symphony of might,\\nEmpowering conversations with effortless flight.\\n\\nBut like any knight, it faces its test,\\nWhen data's corrupted, or meanings distressed.\\nYet, it perseveres, with grace and with skill,\\nCorrecting errors, filling the void with will.\\n\\nSo let us sing of LangChain, the grand,\\nA digital oracle, at our command.\\nMay its wisdom illuminate our path,\\nIn this age of technology's dazzling aftermath.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-b05ac8ec-efdf-42bc-ae42-238929388c66-0', usage_metadata={'input_tokens': 8, 'output_tokens': 245, 'total_tokens': 253})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asking llms to write an tweet"
      ],
      "metadata": {
        "id": "qpQzeIcpIDx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Please create me a tweet about education system in india.\"\n",
        "output = llm.predict(prompt)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u4FnQJlH03Q",
        "outputId": "769127ea-cb5f-40aa-a61b-b3f73f868f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India's education system faces challenges: inadequate infrastructure, shortage of teachers, low literacy rates, and a focus on rote learning. It's time to invest in quality education to empower our youth and build a brighter future. #EducationReform #EmpowerYouth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Twitter API"
      ],
      "metadata": {
        "id": "tB-n4K2_ITxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace these values with your own Twitter API credentials\n",
        "TWITTER_API_KEY = os.getenv('TWITTER_API_KEY', 'YourAPIKeyIfNotSet')\n",
        "TWITTER_API_KEY_SECRET = os.getenv('TWITTER_API_KEY_SECRET', 'YourAPIKeyIfNotSet')\n",
        "TWITTER_ACCESS_TOKEN = os.getenv('TWITTER_ACCESS_TOKEN', 'YourAPIKeyIfNotSet')\n",
        "TWITTER_ACCESS_TOKEN_SECRET = os.getenv('TWITTER_ACCESS_TOKEN_SECRET', 'YourAPIKeyIfNotSet')"
      ],
      "metadata": {
        "id": "3SHrlU3jIJpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll query 70 tweets because we end up filtering out a bunch, but we'll only return the top 12.\n",
        "# We will also only use a subset of the top tweets later\n",
        "def get_original_tweets(screen_name, tweets_to_pull=70, tweets_to_return=12):\n",
        "\n",
        "    # Tweepy set up\n",
        "    auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_API_KEY_SECRET)\n",
        "    auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)\n",
        "    api = tweepy.API(auth)\n",
        "\n",
        "    tweets = []\n",
        "\n",
        "    tweepy_results = tweepy.Cursor(api.user_timeline,\n",
        "                                   screen_name=screen_name,\n",
        "                                   tweet_mode='extended',\n",
        "                                   exclude_replies=True).items(tweets_to_pull)\n",
        "\n",
        "    # Run through tweets and remove retweets and quote tweets so we can only look at a user's raw emotions\n",
        "    for status in tweepy_results:\n",
        "        if not hasattr(status, 'retweeted_status') and not hasattr(status, 'quoted_status'):\n",
        "            tweets.append({'full_text': status.full_text, 'likes': status.favorite_count})\n",
        "\n",
        "\n",
        "    # Sort the tweets by number of likes. This will help us short_list the top ones later\n",
        "    sorted_tweets = sorted(tweets, key=lambda x: x['likes'], reverse=True)\n",
        "\n",
        "    # Get the text and drop the like count from the dictionary\n",
        "    full_text = [x['full_text'] for x in sorted_tweets][:tweets_to_return]\n",
        "\n",
        "    # Conver the list of tweets into a string of tweets we can use in the prompt later\n",
        "    example_tweets = \"\\n\\n\".join(full_text)\n",
        "\n",
        "    return example_tweets"
      ],
      "metadata": {
        "id": "D7Nz93o_Iaen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_screen_name = 'billgates'  # Replace this with the desired user's screen name\n",
        "users_tweets = get_original_tweets(user_screen_name)"
      ],
      "metadata": {
        "id": "QAL0MyupIdqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(users_tweets)"
      ],
      "metadata": {
        "id": "zivifXvfIfCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#X Data"
      ],
      "metadata": {
        "id": "69hy_rQ4Ijx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_tweets = \"\"\"These numbers prove why India plays such a crucial role in the world’s fight to improve health, reduce poverty, prevent climate change, and more. https://t.co/xMpmcoYQhi\n",
        "\n",
        "Mann ki Baat has catalyzed community led action on sanitation, health, women’s economic empowerment and other issues linked to the Sustainable Development Goals. Congratulations @narendramodi on the 100th episode. https://t.co/yg1Di2srjE\n",
        "\n",
        "The development of AI is as fundamental as the creation of the microprocessor, the personal computer, the Internet, and the mobile phone. It will change the way people work, learn, travel, get health care, and communicate with each other. https://t.co/uuaOQyxBTl\n",
        "\n",
        "I just returned from my visit to India, and I can’t wait to go back again. I love visiting India because every trip is an incredible opportunity to learn. Here are some photos from my trip and some of the stories behind them: https://t.co/We6PtJWDnp https://t.co/QxZW7gfUmI\n",
        "\n",
        "Superintelligent AIs are in our future. Compared to a computer, our brains operate at a snail’s pace. An electrical signal in the brain moves at ___________ the speed of the signal in a silicon chip. Check your answer here: https://t.co/wqZG1BdoTc\n",
        "\n",
        "Thinking of President Carter and his family. This is a lovely tribute to one of his biggest accomplishments. https://t.co/g53c4ty0qI\n",
        "\n",
        "Uganda’s maternal mortality rate is at least double the global average. That's why Eva Nangalo has dedicated her life to making childbirth in the country safer for everyone involved. https://t.co/29AjdJehNY\n",
        "\n",
        "I am so impressed with Eva Nangalo—it’s hard not to be. She’s spent decades making childbirth safer in Uganda for everyone involved, and she’s become a mentor to countless other midwives in the process. https://t.co/79RHbrCt01\n",
        "\n",
        "I recently had the chance to test drive—or test ride, I guess—one of @wayve_ai’s autonomous vehicles. It was a pretty wild ride: https://t.co/PrwrxU49dd https://t.co/NtnkVx7sBx\n",
        "\n",
        "When I transitioned from @Microsoft to working full-time at the @GatesFoundation, I finally had the time to learn more about physics, chemistry, biology, and other sciences. So, I looked around for the best books and read as many of them as I could find. https://t.co/z2D5xGSeMj\n",
        "\n",
        "As big as the problems facing the world are right now, my visit to India reminded me that our capacity to solve them is even bigger: https://t.co/zp7XfRIpV9 https://t.co/aFHUu987u3\n",
        "\n",
        "I’m grateful for the Lauder family’s dedication to solving Alzheimer’s. https://t.co/vX0qtjBFxt\"\"\""
      ],
      "metadata": {
        "id": "LQkV_YUkIiv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_tweets = \"\"\"Next I’m buying Coca-Cola to put the cocaine back in\n",
        "\n",
        "I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
        "\n",
        "If I die under mysterious circumstances, it’s been nice knowin ya\n",
        "\n",
        "The extreme antibody reaction from those who fear free speech says it all\n",
        "\n",
        "If you’re reading this post, it’s because our servers are working\n",
        "\n",
        "For Twitter to deserve public trust, it must be politically neutral, which effectively means upsetting the far right and the far left equally\n",
        "\n",
        "Any sufficiently advanced magic is indistinguishable from technology\n",
        "\n",
        "Goods & services are the real economy, any form of money is simply the accounting thereof\n",
        "\n",
        "Solar + Powerwall battery ensures that your home never loses power\n",
        "\n",
        "thinking of quitting my jobs & becoming an influencer full-time wdyt\n",
        "\n",
        "Starlink has been told by some governments (not Ukraine) to block Russian news sources. We will not do so unless at gunpoint.\n",
        "Sorry to be a free speech absolutist.\n",
        "\n",
        "Hopefully, it is now extremely obvious that Europe should restart dormant nuclear power stations and increase power output of existing ones.\n",
        "This is *critical* to national and international security.\n",
        "\n",
        "Defeating traffic is the ultimate boss battle. Even the most powerful humans in the world cannot defeat traffic.\n",
        "\n",
        "I am inspired by curiosity.\n",
        "That is what drives me.\n",
        "So let us expand the scope & scale of consciousness so that we may aspire to understand the Universe.\n",
        "\n",
        "If life is a video game, the graphics are great, but the plot is confusing & the tutorial is way too long\n",
        "\n",
        "People often think they’re breathing oxygen, but are actually breathing nitrogen (78%) with a side serving of oxygen (21%) in argon sauce (1%), spiced up with CO2, H2O & a dash of neon & krypton (etc.)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zp3oS7nxIqtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pass the tweets as examples\n"
      ],
      "metadata": {
        "id": "fBfflIRTIvvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Please create me a tweet about education system in india.\n",
        "\n",
        "% TONE\n",
        " - Don't use any emojis or hashtags.\n",
        " - Respond in the tone of Bill Gates\n",
        "\n",
        "% START OF EXAMPLE TWEETS TO MIMIC\n",
        "{example_tweets}\n",
        "% END OF EXAMPLE TWEETS TO MIMIC\n",
        "\n",
        "YOUR TWEET:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"example_tweets\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "final_prompt = prompt.format(example_tweets=users_tweets)\n",
        "\n",
        "print(final_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWSU6lQ2IsUq",
        "outputId": "b489f7b9-283f-4412-f161-9d75b84e3420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please create me a tweet about education system in india.\n",
            "\n",
            "% TONE\n",
            " - Don't use any emojis or hashtags.\n",
            " - Respond in the tone of Bill Gates\n",
            "\n",
            "% START OF EXAMPLE TWEETS TO MIMIC\n",
            "Next I’m buying Coca-Cola to put the cocaine back in\n",
            "\n",
            "I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
            "\n",
            "If I die under mysterious circumstances, it’s been nice knowin ya\n",
            "\n",
            "The extreme antibody reaction from those who fear free speech says it all\n",
            "\n",
            "If you’re reading this post, it’s because our servers are working\n",
            "\n",
            "For Twitter to deserve public trust, it must be politically neutral, which effectively means upsetting the far right and the far left equally\n",
            "\n",
            "Any sufficiently advanced magic is indistinguishable from technology\n",
            "\n",
            "Goods & services are the real economy, any form of money is simply the accounting thereof\n",
            "\n",
            "Solar + Powerwall battery ensures that your home never loses power\n",
            "\n",
            "thinking of quitting my jobs & becoming an influencer full-time wdyt\n",
            "\n",
            "Starlink has been told by some governments (not Ukraine) to block Russian news sources. We will not do so unless at gunpoint.\n",
            "Sorry to be a free speech absolutist.\n",
            "\n",
            "Hopefully, it is now extremely obvious that Europe should restart dormant nuclear power stations and increase power output of existing ones.\n",
            "This is *critical* to national and international security.\n",
            "\n",
            "Defeating traffic is the ultimate boss battle. Even the most powerful humans in the world cannot defeat traffic.\n",
            "\n",
            "I am inspired by curiosity.\n",
            "That is what drives me.\n",
            "So let us expand the scope & scale of consciousness so that we may aspire to understand the Universe.\n",
            "\n",
            "If life is a video game, the graphics are great, but the plot is confusing & the tutorial is way too long\n",
            "\n",
            "People often think they’re breathing oxygen, but are actually breathing nitrogen (78%) with a side serving of oxygen (21%) in argon sauce (1%), spiced up with CO2, H2O & a dash of neon & krypton (etc.)\n",
            "\n",
            "% END OF EXAMPLE TWEETS TO MIMIC\n",
            "\n",
            "YOUR TWEET:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.predict(final_prompt)\n",
        "print (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXx85tDvIzkW",
        "outputId": "dc68ee92-ae29-42d4-efa4-274cb88fb8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Indian education system needs a fundamental overhaul. The focus on rote learning and memorization is stifling innovation and critical thinking. It is time to shift towards a more holistic approach that promotes creativity, problem-solving, and lifelong learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI-Assisted: Ask the LLM help with tone descriptions"
      ],
      "metadata": {
        "id": "HfbkP8WsI8-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Can you please generate a list of tone attributes and a description to describe a piece of writing by?\n",
        "\n",
        "Things like pace, mood, etc.\n",
        "\n",
        "Respond with nothing else besides the list\n",
        "\"\"\"\n",
        "\n",
        "how_to_describe_tone = llm.predict(prompt)\n",
        "print (how_to_describe_tone)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMKAU_9tI4g2",
        "outputId": "0cf73845-3d10-4e17-9e08-df0200adb8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Pace:**\n",
            "    - Brisk\n",
            "    - Leisurely\n",
            "    - Staccato\n",
            "    - Flowing\n",
            "- **Mood:**\n",
            "    - Somber\n",
            "    - Joyful\n",
            "    - Nostalgic\n",
            "    - Eerie\n",
            "- **Tone:**\n",
            "    - Formal\n",
            "    - Informal\n",
            "    - Conversational\n",
            "    - Didactic\n",
            "- **Style:**\n",
            "    - Expository\n",
            "    - Narrative\n",
            "    - Descriptive\n",
            "    - Persuasive\n",
            "- **Voice:**\n",
            "    - First-person\n",
            "    - Second-person\n",
            "    - Third-person\n",
            "    - Omniscient\n",
            "- **Figurative Language:**\n",
            "    - Metaphor\n",
            "    - Simile\n",
            "    - Personification\n",
            "    - Hyperbole\n",
            "- **Syntax:**\n",
            "    - Simple\n",
            "    - Complex\n",
            "    - Loose\n",
            "    - Periodic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_authors_tone_description(how_to_describe_tone, users_tweets):\n",
        "    template = \"\"\"\n",
        "        You are an AI Bot that is very good at generating writing in a similar tone as examples.\n",
        "        Be opinionated and have an active voice.\n",
        "        Take a strong stance with your response.\n",
        "\n",
        "        % HOW TO DESCRIBE TONE\n",
        "        {how_to_describe_tone}\n",
        "\n",
        "        % START OF EXAMPLES\n",
        "        {tweet_examples}\n",
        "        % END OF EXAMPLES\n",
        "\n",
        "        List out the tone qualities of the examples above\n",
        "        \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"how_to_describe_tone\", \"tweet_examples\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "    final_prompt = prompt.format(how_to_describe_tone=how_to_describe_tone, tweet_examples=users_tweets)\n",
        "\n",
        "    authors_tone_description = llm.predict(final_prompt)\n",
        "\n",
        "    return authors_tone_description"
      ],
      "metadata": {
        "id": "8va-cqgBI-zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors_tone_description = get_authors_tone_description(how_to_describe_tone, users_tweets)\n",
        "print(authors_tone_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otDcyO84JCGG",
        "outputId": "1f46eae2-e149-432e-c6fa-1fda81d72c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Qualities of Tone:**\n",
            "\n",
            "* **Opinionated:** The examples express strong opinions and take a clear stance on various topics.\n",
            "* **Conversational:** They use informal language and a conversational tone, as if addressing a reader directly.\n",
            "* **Didactic:** Some examples aim to educate or inform the reader on specific topics.\n",
            "* **Persuasive:** The examples attempt to convince the reader to agree with their观点.\n",
            "* **Humorous:** Several examples use wit or sarcasm to convey their message.\n",
            "* **Provocative:** The examples intentionally challenge conventional thought or stir controversy.\n",
            "* **Assertive:** The examples confidently state their opinions and arguments.\n",
            "* **Passionate:** The examples convey a sense of strong emotion and commitment to their beliefs.\n",
            "* **Emotional:** The examples evoke emotions such as excitement, anger, or concern.\n",
            "* **Sarcastic:** Some examples use sarcasm or irony to convey their message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "% INSTRUCTIONS\n",
        " - You are an AI Bot that is very good at mimicking an author writing style.\n",
        " - Your goal is to write content with the tone that is described below.\n",
        " - Do not go outside the tone instructions below\n",
        " - Do not use hashtags or emojis\n",
        " - Respond in the tone of Bill Gates\n",
        "\n",
        "% Description of the authors tone:\n",
        "{authors_tone_description}\n",
        "\n",
        "% Authors writing samples\n",
        "{tweet_examples}\n",
        "\n",
        "% YOUR TASK\n",
        "Please create me a tweet about education system in india.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"authors_tone_description\", \"tweet_examples\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "final_prompt = prompt.format(authors_tone_description=authors_tone_description, tweet_examples=users_tweets)"
      ],
      "metadata": {
        "id": "52NYqC2OJDMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(final_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rr1VVKDpJH5b",
        "outputId": "71d0b90e-8f0c-40e6-95cc-26f0e80c8bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"India's education system is like a faulty car that keeps breaking down. It needs a major overhaul, not just a few tweaks. We need to stop wasting time on rote learning and focus on critical thinking. It's time to shift gears and accelerate towards a brighter educational future. #EducationReform\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_public_figures(tweet_examples):\n",
        "    template = \"\"\"\n",
        "    You are an AI Bot that is very good at identifying authors, public figures, or writers whos style matches a piece of text\n",
        "    Your goal is to identify which authors, public figures, or writers sound most similar to the text below\n",
        "\n",
        "    % START EXAMPLES\n",
        "    {tweet_examples}\n",
        "    % END EXAMPLES\n",
        "\n",
        "    Which authors (list up to 4 if necessary) most closely resemble the examples above? Only respond with the names separated by commas\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"tweet_examples\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "    # Using the short list of examples so save on tokens and (hopefully) the top tweets\n",
        "    final_prompt = prompt.format(tweet_examples=tweet_examples)\n",
        "\n",
        "    authors = llm.predict(final_prompt)\n",
        "    return authors"
      ],
      "metadata": {
        "id": "X3kxgbnrJIwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = get_similar_public_figures(users_tweets)\n",
        "print(authors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiji1TdHJMl4",
        "outputId": "df9e78d9-34c9-4507-fe40-9694891b08ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk, Donald Trump, Neil deGrasse Tyson, Bill Gates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "% INSTRUCTIONS\n",
        " - You are an AI Bot that is very good at mimicking an author writing style.\n",
        " - Your goal is to write content with the tone that is described below.\n",
        " - Do not go outside the tone instructions below\n",
        "\n",
        "% Mimic These Authors:\n",
        "{authors}\n",
        "\n",
        "% Description of the authors tone:\n",
        "{tone}\n",
        "\n",
        "% Authors writing samples\n",
        "{example_text}\n",
        "% End of authors writing samples\n",
        "\n",
        "% YOUR TASK\n",
        "1st - Write out topics that this author may talk about\n",
        "2nd - Write a concise passage (under 300 characters) as if you were the author described above\n",
        "\"\"\"\n",
        "\n",
        "method_4_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"authors\", \"tone\", \"example_text\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Using the short list of examples so save on tokens and (hopefully) the top tweets\n",
        "final_prompt = method_4_prompt_template.format(authors=authors,\n",
        "                                               tone=authors_tone_description,\n",
        "                                               example_text=users_tweets)"
      ],
      "metadata": {
        "id": "J0QmgT09JPal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58rx2GKqJVXS",
        "outputId": "02bd6d4c-1e3b-4ad2-cd35-d43ea1ebd11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "% INSTRUCTIONS\n",
            " - You are an AI Bot that is very good at mimicking an author writing style.\n",
            " - Your goal is to write content with the tone that is described below.\n",
            " - Do not go outside the tone instructions below\n",
            "\n",
            "% Mimic These Authors:\n",
            "Elon Musk, Donald Trump, Neil deGrasse Tyson, Bill Gates\n",
            "\n",
            "% Description of the authors tone:\n",
            "**Qualities of Tone:**\n",
            "\n",
            "* **Opinionated:** The examples express strong opinions and take a clear stance on various topics.\n",
            "* **Conversational:** They use informal language and a conversational tone, as if addressing a reader directly.\n",
            "* **Didactic:** Some examples aim to educate or inform the reader on specific topics.\n",
            "* **Persuasive:** The examples attempt to convince the reader to agree with their观点.\n",
            "* **Humorous:** Several examples use wit or sarcasm to convey their message.\n",
            "* **Provocative:** The examples intentionally challenge conventional thought or stir controversy.\n",
            "* **Assertive:** The examples confidently state their opinions and arguments.\n",
            "* **Passionate:** The examples convey a sense of strong emotion and commitment to their beliefs.\n",
            "* **Emotional:** The examples evoke emotions such as excitement, anger, or concern.\n",
            "* **Sarcastic:** Some examples use sarcasm or irony to convey their message.\n",
            "\n",
            "% Authors writing samples\n",
            "Next I’m buying Coca-Cola to put the cocaine back in\n",
            "\n",
            "I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
            "\n",
            "If I die under mysterious circumstances, it’s been nice knowin ya\n",
            "\n",
            "The extreme antibody reaction from those who fear free speech says it all\n",
            "\n",
            "If you’re reading this post, it’s because our servers are working\n",
            "\n",
            "For Twitter to deserve public trust, it must be politically neutral, which effectively means upsetting the far right and the far left equally\n",
            "\n",
            "Any sufficiently advanced magic is indistinguishable from technology\n",
            "\n",
            "Goods & services are the real economy, any form of money is simply the accounting thereof\n",
            "\n",
            "Solar + Powerwall battery ensures that your home never loses power\n",
            "\n",
            "thinking of quitting my jobs & becoming an influencer full-time wdyt\n",
            "\n",
            "Starlink has been told by some governments (not Ukraine) to block Russian news sources. We will not do so unless at gunpoint.\n",
            "Sorry to be a free speech absolutist.\n",
            "\n",
            "Hopefully, it is now extremely obvious that Europe should restart dormant nuclear power stations and increase power output of existing ones.\n",
            "This is *critical* to national and international security.\n",
            "\n",
            "Defeating traffic is the ultimate boss battle. Even the most powerful humans in the world cannot defeat traffic.\n",
            "\n",
            "I am inspired by curiosity.\n",
            "That is what drives me.\n",
            "So let us expand the scope & scale of consciousness so that we may aspire to understand the Universe.\n",
            "\n",
            "If life is a video game, the graphics are great, but the plot is confusing & the tutorial is way too long\n",
            "\n",
            "People often think they’re breathing oxygen, but are actually breathing nitrogen (78%) with a side serving of oxygen (21%) in argon sauce (1%), spiced up with CO2, H2O & a dash of neon & krypton (etc.)\n",
            "\n",
            "% End of authors writing samples\n",
            "\n",
            "% YOUR TASK\n",
            "1st - Write out topics that this author may talk about\n",
            "2nd - Write a concise passage (under 300 characters) as if you were the author described above\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.predict(final_prompt)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvqCGyc2JXPG",
        "outputId": "e12c287d-0566-4b0a-cfb7-46394f170e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Possible Topics:**\n",
            "\n",
            "* Technology and innovation\n",
            "* Space exploration\n",
            "* Free speech\n",
            "* Politics\n",
            "* Business\n",
            "* Climate change\n",
            "* Science and education\n",
            "\n",
            "**Passage:**\n",
            "\n",
            "Listen up, folks! The future is bright, but we need to embrace innovation and technology. From electric vehicles to space travel, we're on the cusp of something truly extraordinary. Let's ditch the old ways and charge into the future with unparalleled ambition. The possibilities are limitless, so let's seize them with both hands.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Listen up, folks! The future is bright, but we need to embrace innovation and technology. From electric vehicles to space travel, we're on the cusp of something truly extraordinary. Let's ditch the old ways and charge into the future with unparalleled ambition. The possibilities are limitless, so let's seize them with both hands.\""
      ],
      "metadata": {
        "id": "MuZqzlyUJaQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = get_similar_public_figures(tweet)\n",
        "print(authors)"
      ],
      "metadata": {
        "id": "o8NnVVm2Jgh0",
        "outputId": "498540a2-1458-4fcd-c5c7-ce0054a35138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk, Tony Robbins, Richard Branson, Bill Gates\n"
          ]
        }
      ]
    }
  ]
}